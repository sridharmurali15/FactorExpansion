{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c3c0fd0c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "import tensorflow as tf\n",
        "from keras.layers import *\n",
        "from tensorflow.keras import optimizers\n",
        "from keras import Model\n",
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.metrics import mean_squared_error"
      ],
      "id": "c3c0fd0c"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "65aae4f6"
      },
      "outputs": [],
      "source": [
        "with urllib.request.urlopen(\"https://scale-static-assets.s3-us-west-2.amazonaws.com/ml-interview/expand/train.txt\") as url:\n",
        "    data = url.read()"
      ],
      "id": "65aae4f6"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "50d14532"
      },
      "outputs": [],
      "source": [
        "data = data.decode('utf-8')\n",
        "data = data.split('\\n')\n",
        "np.random.shuffle(data)\n",
        "factors, expansion = [], []\n",
        "for item in data:\n",
        "    temp = item.split('=')\n",
        "    if temp!=['']:\n",
        "        factors.append(temp[0])\n",
        "        expansion.append(temp[1])"
      ],
      "id": "50d14532"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "86267410"
      },
      "outputs": [],
      "source": [
        "vocab = {' ':0,'<START>':1, '<END>':2}\n",
        "vocab.update({str(i):i+3 for i in range(10)})\n",
        "vocab.update({item.strip():i+13 for i,item in enumerate('a, c, h, i, j, k, n, o, s, t, x, y, z'.split(','))})\n",
        "vocab.update({'sin':26, 'cos':27, 'tan': 28, '+':29, '-':30, '*':31, '/':32, '**':33, '(':34, ')':35})"
      ],
      "id": "86267410"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4be76567"
      },
      "outputs": [],
      "source": [
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them based on the vocabulary created\n",
        "    + Decode the representation to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        # initialize the character table\n",
        "        self.chars = list(chars)\n",
        "        self.char_indices = chars\n",
        "        self.indices_char = {v:k for k,v in self.char_indices.items()}\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        x = np.array([self.char_indices[c] for i, c in enumerate(C)])\n",
        "        x = np.concatenate((x, np.zeros((1,num_rows-len(x)))), axis=None)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        return [self.indices_char[c] for c in x]"
      ],
      "id": "4be76567"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6faca8e1"
      },
      "outputs": [],
      "source": [
        "ctable = CharacterTable(vocab)"
      ],
      "id": "6faca8e1"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0bc30a02"
      },
      "outputs": [],
      "source": [
        "x = np.array([ctable.encode(item,29) for item in factors])\n",
        "y = []\n",
        "for i in range(len(expansion)):\n",
        "    temp = np.append(ctable.encode(expansion[i],len(expansion[i])), ctable.char_indices['<END>'], axis=None)\n",
        "    temp = np.append(temp, [0]*(28-len(expansion[i])), axis=None)\n",
        "    y.append(temp)\n",
        "y = np.array(y)\n",
        "y = np.hstack([np.reshape(np.ones(len(y)),(-1,1)), y])"
      ],
      "id": "0bc30a02"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "125814d6"
      },
      "source": [
        "------------------------------------------------------------------------------------------------------------"
      ],
      "id": "125814d6"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dc113fd5"
      },
      "outputs": [],
      "source": [
        "# attention model\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "id": "dc113fd5"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7059a5d0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Concatenate\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "# Encoder input\n",
        "encoder_inputs = Input(shape=(29,)) \n",
        "\n",
        "# Embedding layer- i am using 1024 output-dim for embedding you can try diff values 100,256,512,1000\n",
        "enc_emb = Embedding(len(vocab), 654)(encoder_inputs)\n",
        "\n",
        "# Bidirectional lstm layer\n",
        "enc_lstm1 = Bidirectional(LSTM(256,return_sequences=True,return_state=True))\n",
        "encoder_outputs1, forw_state_h, forw_state_c, back_state_h, back_state_c = enc_lstm1(enc_emb)\n",
        "\n",
        "# Concatenate both h and c \n",
        "final_enc_h = Concatenate()([forw_state_h,back_state_h])\n",
        "final_enc_c = Concatenate()([forw_state_c,back_state_c])\n",
        "\n",
        "# get Context vector\n",
        "encoder_states =[final_enc_h, final_enc_c]"
      ],
      "id": "7059a5d0"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "429b0b2e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "decoder_inputs = Input(shape=(None,)) \n",
        "\n",
        "# decoder embedding with same number as encoder embedding\n",
        "dec_emb_layer = Embedding(len(vocab), 654) \n",
        "dec_emb = dec_emb_layer(decoder_inputs)   # apply this way because we need embedding layer for prediction \n",
        "\n",
        "# In encoder we used Bidirectional so it's having two LSTM's so we have to take double units(256*2=512) for single decoder lstm\n",
        "# LSTM using encoder's final states as initial state\n",
        "decoder_lstm = LSTM(512, return_sequences=True, return_state=True) \n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "# Using Attention Layer\n",
        "attention_layer = AttentionLayer()\n",
        "attention_result, attention_weights = attention_layer([encoder_outputs1, decoder_outputs])\n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_result])\n",
        "# Dense layer with softmax\n",
        "decoder_dense = Dense(len(vocab), activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "id": "429b0b2e"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "73e0fd4c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y, train_size=0.8)"
      ],
      "id": "73e0fd4c"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28958d1c",
        "scrolled": true,
        "outputId": "03d859e8-4a9a-42b2-86d4-26531a04910a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 29)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 29, 654)      23544       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  [(None, 29, 512),    1865728     ['embedding[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 654)    23544       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 512)          0           ['bidirectional[0][1]',          \n",
            "                                                                  'bidirectional[0][3]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 512)          0           ['bidirectional[0][2]',          \n",
            "                                                                  'bidirectional[0][4]']          \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 512),  2390016     ['embedding_1[0][0]',            \n",
            "                                 (None, 512),                     'concatenate[0][0]',            \n",
            "                                 (None, 512)]                     'concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, None, 512),  524800     ['bidirectional[0][0]',          \n",
            " r)                              (None, None, 29))                'lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 1024)   0           ['lstm_1[0][0]',                 \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 36)     36900       ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,864,532\n",
            "Trainable params: 4,864,532\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# compile model\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"give Your path to save check points\", monitor='val_accuracy')\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "callbacks_list = [checkpoint, early_stopping]\n",
        "\n",
        "# Training set\n",
        "encoder_input_data = X_train\n",
        "\n",
        "# To make same as target data skip last number which is just padding\n",
        "decoder_input_data = y_train[:,:-1]\n",
        "\n",
        "# Decoder target data has to be one step ahead so we are taking from 1 as told in keras docs\n",
        "decoder_target_data =  y_train[:,1:]\n",
        "\n",
        "# devlopment set\n",
        "encoder_input_test = X_test\n",
        "decoder_input_test = y_test[:,:-1]\n",
        "decoder_target_test=  y_test[:,1:]\n",
        "\n",
        "model.summary()\n",
        "EPOCHS= 1\n",
        "history = model.fit([encoder_input_data, decoder_input_data],decoder_target_data, \n",
        "                    epochs=EPOCHS, \n",
        "                    batch_size=128,\n",
        "                    validation_data = ([encoder_input_test, decoder_input_test],decoder_target_test),\n",
        "                    callbacks= callbacks_list)\n",
        "\n",
        "# Don't forget to save weights of trained model \n",
        "model.save(\"model_new.h5\") # can give whole path to save model"
      ],
      "id": "28958d1c"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "37b98931"
      },
      "outputs": [],
      "source": [
        "del model \n",
        "custom_obj = {\"CustomLayer\": AttentionLayer}\n",
        "model = load_model('model_new.h5', custom_objects={'AttentionLayer': AttentionLayer})\n",
        "\n",
        "encoder_model = Model(encoder_inputs, outputs = [encoder_outputs1, final_enc_h, final_enc_c])\n",
        "\n",
        "# Decoder Inference\n",
        "decoder_state_h = Input(shape=(512,)) # This numbers has to be same as units of lstm's on which model is trained\n",
        "decoder_state_c = Input(shape=(512,))\n",
        "\n",
        "# we need hidden state for attention layer\n",
        "decoder_hidden_state_input = Input(shape=(29,512)) \n",
        "# get decoder states\n",
        "dec_states = [decoder_state_h, decoder_state_c]\n",
        "\n",
        "# embedding layer \n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=dec_states)\n",
        "\n",
        "# Attention inference\n",
        "attention_result_inf, attention_weights_inf = attention_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_concat_input_inf = Concatenate(axis=-1, name='concat_layer')([decoder_outputs2, attention_result_inf])\n",
        "\n",
        "dec_states2= [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_concat_input_inf)\n",
        "\n",
        "# get decoder model\n",
        "decoder_model= Model(\n",
        "                    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_h, decoder_state_c],\n",
        "                     [decoder_outputs2]+ dec_states2)"
      ],
      "id": "37b98931"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Pu49RK8wVcsJ"
      },
      "outputs": [],
      "source": [
        "def get_predicted_sentence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    enc_output, enc_h, enc_c = encoder_model.predict(input_seq)\n",
        "    # print('------DONE ENCODING------')\n",
        "  \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # print('------DONE EMPTY TARGET------')\n",
        "    \n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = vocab['<START>']\n",
        "    # print('------DONE START TAG------')\n",
        "    \n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [enc_output, enc_h, enc_c ])\n",
        "        # print('------DONE OUTPUT TOKEN------')\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        # print('------DONE SAMPLE TOKEN------')\n",
        "        # convert max index number to marathi word\n",
        "        sampled_char = ctable.indices_char[sampled_token_index]\n",
        "        # print('------DONE CONVERT TOKEN------')\n",
        "        # aapend it to decoded sent\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "        # print('------DONE APPEND TOKEN------')\n",
        "        \n",
        "        # Exit condition: either hit max length or find stop token.\n",
        "        if (sampled_char == '<END>' or len(decoded_sentence.split()) >= 29):\n",
        "            stop_condition = True\n",
        "            # print('------DONE STOP------')\n",
        "        \n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        \n",
        "        # Update states\n",
        "        enc_h, enc_c = h, c\n",
        "    \n",
        "    return decoded_sentence"
      ],
      "id": "Pu49RK8wVcsJ"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ai-qMnftYDMI"
      },
      "outputs": [],
      "source": [
        "temp = [np.random.choice(10) for i in range(20)]"
      ],
      "id": "ai-qMnftYDMI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJc4y4mMVsf4"
      },
      "outputs": [],
      "source": [
        "for i in temp:\n",
        "    print('TRUE: ', ''.join(ctable.decode(y_test[i][1:])), '------------ ', 'PRED: ', ''.join(get_predicted_sentence(X_test[i].reshape(1,29)).split()[:-1]))"
      ],
      "id": "sJc4y4mMVsf4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_57oejCEtoGP",
        "outputId": "5ab3aae6-8921-47c7-db4e-756c5d5e933e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "encoder_model.save('encoder.h5')\n",
        "encoder_model.save('decoder.h5')"
      ],
      "id": "_57oejCEtoGP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_Xch9yv9oK0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('encoder.h5') \n",
        "files.download('decoder.h5') "
      ],
      "id": "h_Xch9yv9oK0"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "geekculture_neural_machine_translation_using_seq2seq_model_with_attention_testx.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}